{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise\n",
    "\n",
    "What if we could get a set of word and images to be in the same space\n",
    "\n",
    "```\n",
    "beagle dog input --> model A --> jumbo jet\n",
    "beagle dog input --> model B --> corgie\n",
    "```\n",
    "Consider models A and B. In traditional terms, both of these models are wrong (have the same score). But in word vector space, corgie (a dog) is much closer to beagle, so model B is much better than model A\n",
    "\n",
    "**idea** - train a model that finds a word vector for the word you want. Instead of class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from fastai.conv_learner import *\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "import fastText as ft\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup our paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/imagenet/')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TRANS_PATH = Path('data/translate/')\n",
    "PATH_TRN = PATH/'train'\n",
    "fname = 'valid/n01440764/ILSVRC2012_val_00007197.JPEG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vecs = ft.load_model(str((TRANS_PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03259, -0.18164, -0.29049, -0.10506, -0.16712, -0.07748, -0.5661 , -0.08622, -0.00216,  0.15366],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_vecs.get_word_vector('king')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519370"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_words = ft_vecs.get_words(include_freq=True)\n",
    "ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "\n",
    "len(ft_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Imagenet Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imagenet_class_index.json: 41.0kB [00:00, 162kB/s]                             \n"
     ]
    }
   ],
   "source": [
    "CLASSES_FN = 'imagenet_class_index.json'\n",
    "get_data(f'http://files.fast.ai/models/{CLASSES_FN}', TMP_PATH/CLASSES_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all nouns in English (WORDNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classids.txt: 1.74MB [00:01, 1.70MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "WORDS_FN = 'classids.txt'\n",
    "get_data(f'http://files.fast.ai/data/{WORDS_FN}', PATH/WORDS_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create imagenet class number to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = json.load((TMP_PATH/CLASSES_FN).open())\n",
    "classids_1k = dict(class_dict.values())\n",
    "nclass = len(class_dict); nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n01440764', 'tench']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet class number to Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n00001740 entity\\n',\n",
       " 'n00001930 physical_entity\\n',\n",
       " 'n00002137 abstraction\\n',\n",
       " 'n00002452 thing\\n',\n",
       " 'n00002684 object\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classid_lines = (PATH/WORDS_FN).open().readlines()\n",
    "classid_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82115, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classids = dict(l.strip().split() for l in classid_lines)\n",
    "len(classids),len(classids_1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look up all teh nouns in FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49469"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_vec_d = {w.lower(): ft_vecs.get_word_vector(w) for w in ft_words[-1000000:]}\n",
    "syn_wv = [(k, lc_vec_d[v.lower()]) for k,v in classids.items()\n",
    "          if v.lower() in lc_vec_d]\n",
    "syn_wv_1k = [(k, lc_vec_d[v.lower()]) for k,v in classids_1k.items()\n",
    "          if v.lower() in lc_vec_d]\n",
    "syn2wv = dict(syn_wv)\n",
    "len(syn2wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the lookups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(syn2wv, (TMP_PATH/'syn2wv.pkl').open('wb'))\n",
    "pickle.dump(syn_wv_1k, (TMP_PATH/'syn_wv_1k.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKPOINT load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn2wv = pickle.load((TMP_PATH/'syn2wv.pkl').open('rb'))\n",
    "syn_wv_1k = pickle.load((TMP_PATH/'syn_wv_1k.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to Imagenet Localization data = 157GB, will not run the rest of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "img_vecs = []\n",
    "\n",
    "for d in (PATH/'train').iterdir():\n",
    "    if d.name not in syn2wv: continue\n",
    "    \n",
    "    # grab the fast txt word vector\n",
    "    vec = syn2wv[d.name]\n",
    "    for f in d.iterdir():\n",
    "        images.append(str(f.relative_to(PATH)))\n",
    "        img_vecs.append(vec)\n",
    "\n",
    "n_val=0\n",
    "for d in (PATH/'valid').iterdir():\n",
    "    if d.name not in syn2wv: continue\n",
    "    vec = syn2wv[d.name]\n",
    "    for f in d.iterdir():\n",
    "        images.append(str(f.relative_to(PATH)))\n",
    "        img_vecs.append(vec)\n",
    "        n_val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vecs = np.stack(img_vecs)\n",
    "img_vecs.shapeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(images, (TMP_PATH/'images.pkl').open('wb'))\n",
    "pickle.dump(img_vecs, (TMP_PATH/'img_vecs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images for ImageNet\n",
    "images = pickle.load((TMP_PATH/'images.pkl').open('rb'))\n",
    "\n",
    "# have the corresponding vector for each image\n",
    "img_vecs = pickle.load((TMP_PATH/'img_vecs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model architecture + datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(images); n\n",
    "val_idxs = list(range(n-28650, n))\n",
    "\n",
    "tfms = tfms_from_model(arch, 224, transforms_side_on, max_zoom=1.1)\n",
    "\n",
    "# we can pass all the names from imagenet + word vecs\n",
    "# then pass the indexes\n",
    "# continuous = True - since we are predicting vectors\n",
    "md = ImageClassifierData.from_names_and_array(PATH, images, img_vecs, val_idxs=val_idxs,\n",
    "        classes=None, tfms=tfms, continuous=True, bs=256)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "arch     - resnet 50\n",
    "md.c     - how many classes\n",
    "is_multi - not multiclass\n",
    "is_reg   - is regression\n",
    "xtra_fc  - extra fully connected layers\n",
    "ps       - how much dropout do you want?\n",
    "*note no softmax\n",
    "\"\"\"\n",
    "arch = resnet50\n",
    "models = ConvnetBuilder(arch, md.c, is_multi=False, is_reg=True, xtra_fc=[1024], ps=[0.2,0.2])\n",
    "learn = ConvLearner(md, models, precompute=True)\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.9,0.99))\n",
    "\n",
    "\n",
    "# loss function - L1 loss is the difference\n",
    "# but since we are doing high-dimensional vectors, most of the items\n",
    "# are on the outside and the distance metric isn't the best metricb\n",
    "def cos_loss(inp,targ): return 1 - F.cosine_similarity(inp,targ).mean()\n",
    "learn.crit = cos_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with `precompute=True` to cut down on training time \n",
    "\n",
    "Quoted at 1+ hour length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-4, end_lr=1e15)\n",
    "learn.sched.plot()\n",
    "\n",
    "lr = 1e-2\n",
    "wd = 1e-7\n",
    "learn.precompute=True\n",
    "learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))\n",
    "\n",
    "learn.bn_freeze(True)\n",
    "learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))\n",
    "\n",
    "lrs = np.array([lr/1000,lr/100,lr])\n",
    "learn.precompute=False\n",
    "learn.freeze_to(1)\n",
    "\n",
    "learn.save('pre0')\n",
    "learn.load('pre0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns, wvs = list(zip(*syn_wv_1k))\n",
    "wvs = np.array(wvs)\n",
    "\n",
    "%time pred_wv = learn.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at some of the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = md.val_ds.denorm\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def show_imgs(ims, cols, figsize=None):\n",
    "    fig,axes = plt.subplots(len(ims)//cols, cols, figsize=figsize)\n",
    "    for i,ax in enumerate(axes.flat): show_img(ims[i], ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "start=300\n",
    "show_imgs(denorm(md.val_ds[start:start+25][0]), 5, (10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/OtP8k1.jpg' style='width:700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Nearest Neighbors search - 300D vector, what are the closest neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nmslib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-426fb459f5cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# super fast library, that searches very quickly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnmslib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'angulardist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nmslib'"
     ]
    }
   ],
   "source": [
    "# super fast library, that searches very quickly\n",
    "import nmslib\n",
    "\n",
    "def create_index(a):\n",
    "    index = nmslib.init(space='angulardist')\n",
    "    index.addDataPointBatch(a)\n",
    "    index.createIndex()\n",
    "    return index\n",
    "\n",
    "def get_knns(index, vecs):\n",
    "     return zip(*index.knnQueryBatch(vecs, k=10, num_threads=4))\n",
    "\n",
    "def get_knn(index, vec): return index.knnQuery(vec, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wvs = create_index(wvs)\n",
    "idxs,dists = get_knns(nn_wvs, pred_wv)\n",
    "[[classids[syns[id]] for id in ids[:3]] for ids in idxs[start:start+10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we now bring in WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_syns, all_wvs = list(zip(*syn2wv.items()))\n",
    "all_wvs = np.array(all_wvs)\n",
    "\n",
    "nn_allwvs = create_index(all_wvs)\n",
    "idxs,dists = get_knns(nn_allwvs, pred_wv)\n",
    "[[classids[all_syns[id]] for id in ids[:3]] for ids in idxs[start:start+10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text --> Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predwv = create_index(pred_wv)\n",
    "en_vecd = pickle.load(open(TRANS_PATH/'wiki.en.pkl','rb'))\n",
    "\n",
    "## get the vector for boat\n",
    "vec = en_vecd['boat']\n",
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "\n",
    "# then we only pull images who's  vector is close to our 'boat' vector\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/bsOHQ4.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = (en_vecd['engine'] + en_vecd['boat'])/2\n",
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/eqK8dz.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = (en_vecd['sail'] + en_vecd['boat'])/2\n",
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/Bz6Hsw.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

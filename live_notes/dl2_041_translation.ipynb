{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating French into English\n",
    "\n",
    "- 1. Data <- `x = french,y = english sentences`\n",
    "- 2. Architecture\n",
    "- 3. Suitable loss function\n",
    "\n",
    "### Data\n",
    "\n",
    "Need a parallel corpus, we need pairs of french tuples vs. english tuples. Anything that goes through the UN has many translations. But for french, any canadian website has a french and english versions. So from scrubbing those websites we have a large set of data.\n",
    "\n",
    "#### For bounding boxes, all the interesting stuff was in the loss function, for neural translation, all the interesting stuff will be in the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Fr model for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz (39.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 39.8MB 100.3MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
      "  Running setup.py install for fr-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fr-core-news-sm-2.0.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/fr_core_news_sm\n",
      "    -->\n",
      "    /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data (2.4 GB) / Setup the directory\n",
    "~ 30 mins to download at 1MB/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 00:49:07--  http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
      "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2595102720 (2.4G) [application/x-tar]\n",
      "Saving to: ‘training-giga-fren.tar’\n",
      "\n",
      "training-giga-fren. 100%[===================>]   2.42G   149KB/s    in 47m 17s \n",
      "\n",
      "2018-05-15 01:36:24 (893 KB/s) - ‘training-giga-fren.tar’ saved [2595102720/2595102720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.statmt.org/wmt10/training-giga-fren.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/translate/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv training-giga-fren.tar data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf data/translate/training-giga-fren.tar -C data/translate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip data/translate/giga-fren.release2.fixed.en.gz\n",
    "!gunzip data/translate/giga-fren.release2.fixed.fr.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giga-fren.release2.fixed.en  tmp\r\n",
      "giga-fren.release2.fixed.fr  training-giga-fren.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/translate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Model takes a long time\n",
    "\n",
    "- Google's model has 8 layers\n",
    "- we are going to build a simpler one \n",
    "- Instead of a general model we will translate French questions\n",
    "\n",
    "### Tokenizing and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question regex search filters\n",
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "# grabbling lines from the english and french source texts\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "# isolate the questions\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]\n",
    "\n",
    "# save the questions for later\n",
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       "  ('Who are we?', 'Où sommes-nous?'),\n",
       "  ('Where did we come from?', \"D'où venons-nous?\"),\n",
       "  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       "  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "   'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')],\n",
       " 52331)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in pickled questions\n",
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))\n",
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that tokenizing for french is much different compared to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what', 'is', 'light', '?'],\n",
       " ['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize all the questions\n",
    "en_qs,fr_qs = zip(*qs)\n",
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))\n",
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')\n",
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are keeping tokens that are less than 30 chars\n",
    "# The filter is applied on the english words, and the same tokens are kept for french\n",
    "keep = np.array([len(o)<30 for o in en_tok])\n",
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]\n",
    "\n",
    "# save our work\n",
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    \"\"\"\n",
    "    Swaps out tokens for their index representations\n",
    "    \"\"\"\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    \n",
    "    # beginning of stream \n",
    "    itos.insert(0, '_bos_')\n",
    "    \n",
    "    # padding \n",
    "    itos.insert(1, '_pad_')\n",
    "    \n",
    "    # end of stream\n",
    "    itos.insert(2, '_eos_')\n",
    "    \n",
    "    # unknown\n",
    "    itos.insert(3, '_unk')\n",
    "    \n",
    "    # string to integer (STOI)\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi\n",
    "\n",
    "def load_ids(pre):\n",
    "    \"\"\"\n",
    "    Loading the id mapping from disk\n",
    "    \"\"\"\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))\n",
    "\n",
    "# simultaneously create and save token to indexing\n",
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')\n",
    "\n",
    "# loading lookups from scratch\n",
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 02:23:28--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.28.97\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.28.97|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10356881291 (9.6G) [application/zip]\n",
      "Saving to: ‘wiki.en.zip’\n",
      "\n",
      "wiki.en.zip         100%[===================>]   9.65G  64.1MB/s    in 2m 44s  \n",
      "\n",
      "2018-05-15 02:26:12 (60.2 MB/s) - ‘wiki.en.zip’ saved [10356881291/10356881291]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 02:26:12--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.113\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5975701653 (5.6G) [application/zip]\n",
      "Saving to: ‘wiki.fr.zip’\n",
      "\n",
      "wiki.fr.zip         100%[===================>]   5.56G  65.3MB/s    in 1m 44s  \n",
      "\n",
      "2018-05-15 02:27:57 (54.6 MB/s) - ‘wiki.fr.zip’ saved [5975701653/5975701653]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.en.zip\n",
      "  inflating: wiki.en.vec             \n",
      "  inflating: wiki.en.bin             \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.en.zip -C data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.fr.zip\n",
      "  inflating: wiki.fr.vec             \n",
      "  inflating: wiki.fr.bin             \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.fr.zip -C data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/fastText.git\n",
      "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-dxq_lk8g\n",
      "Requirement already satisfied (use --upgrade to upgrade): fasttext==0.8.22 from git+https://github.com/facebookresearch/fastText.git in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (2.2.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (39.1.0)\n",
      "Requirement already satisfied: numpy in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (1.14.3)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Running setup.py bdist_wheel for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-1ctapqn4/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
      "Successfully built fasttext\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mkaggle-cli 0.12.13 has requirement lxml<4.1,>=4.0.0, but you'll have lxml 4.1.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft\n",
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))\n",
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a lookup per word to get the associated word vector\n",
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd\n",
    "\n",
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))\n",
    "\n",
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec\n",
    "\n",
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to exclude the extreme cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "\n",
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Dataset, DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)\n",
    "    \n",
    "# split the training and testing set\n",
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep], fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep], fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)\n",
    "\n",
    "# create our training and validation sets\n",
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)\n",
    "\n",
    "# set our batch size\n",
    "bs=125\n",
    "\n",
    "\"\"\"\n",
    "- Most of our preprocessing is complete so numworkers = 1\n",
    "- Padding will pad the shorter phrases to be the same length\n",
    "- Decoder, padding at the end\n",
    "- Sampler -  so we keep the similar sentences together (sorted by length) \n",
    "\"\"\"\n",
    "# arranges sentences so that similar lengths are close to each other\n",
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))\n",
    "\n",
    "# create dataloaders\n",
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 11), (21, 7), (21, 8), (33, 13), (33, 21)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek:\n",
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<img src='https://snag.gy/d6yPXD.jpg' style='width:500px'>\n",
    "\n",
    "A sequence will be parsed and encoded in the RNN and will be fed to a hidden state, and then will need to be passed to a decoder that will walk through the words one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    \"\"\"\n",
    "    Creates embedding:\n",
    "    1. rows = number of vocab\n",
    "    2. cols = embedding size dimension\n",
    "    Will randomly initialize the embedding\n",
    "    \"\"\"\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    \n",
    "    # goes through the embedding and replace\n",
    "    # the initialized weights with existing word vectors\n",
    "    # multiply x3 to compensate for the stdev 0.3\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb\n",
    "\n",
    "\n",
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder (enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        \n",
    "        # for each word, pull up the 300M vector and create an embedding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        \n",
    "        # Gru - similiar to LSTM\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        \n",
    "        # decoder (dec)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        \n",
    "        # initialize the hidden layer\n",
    "        h = self.initHidden(bs)\n",
    "        \n",
    "        # run the input through our embeddings + apply dropout\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        \n",
    "        # run it through the RNN layer\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        \n",
    "        # run the hidden state through our linear layer\n",
    "        h = self.out_enc(h)\n",
    "        \n",
    "        # ==================================================\n",
    "        # Decoder version\n",
    "        # ==================================================\n",
    "        \n",
    "        # starting with a 0 (or beginning of string _BOS_)\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        \n",
    "        # will loop as long as the longest english sentence\n",
    "        for i in range(self.out_sl):\n",
    "            \n",
    "            # embedding - we are only looking at a section at time\n",
    "            # which is why the .unsqueeze is required\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            \n",
    "            # rnn - typically works with whole phrases, but we passing\n",
    "            # only 1 unit at a time in a loop\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            \n",
    "            # dropout\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            \n",
    "            # highest probability word\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            \n",
    "            # if its padding ,we are at the end of the sentence\n",
    "            if (dec_inp==1).all(): break\n",
    "                \n",
    "        # stack the output into a single tensor\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))\n",
    "    \n",
    "\n",
    "def seq2seq_loss(input, target):\n",
    "    \"\"\"\n",
    "    Loss function - modified version of cross entropy\n",
    "    \"\"\"\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    \n",
    "    # sequence lenght could be shorter than the original\n",
    "    # need to add padding to even out the size\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "nh,nl = 256,2\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432acc9a8413438995e3c9b843c31289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 243/362 [00:33<00:16,  7.20it/s, loss=34.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model (15-20 mins to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621be1826a904b69b0fb34eaa6e6fdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.112498   5.656483  \n",
      "    1      4.331283   4.427685                              \n",
      "    2      3.890464   4.160612                              \n",
      "    3      3.613806   3.932455                              \n",
      "    4      3.428558   3.742856                              \n",
      "    5      3.352585   3.64594                               \n",
      "    6      2.988233   3.577188                              \n",
      "    7      2.938967   3.563399                              \n",
      "    8      2.957511   3.503175                              \n",
      "    9      2.996382   3.508209                              \n",
      "    10     2.666585   3.522618                              \n",
      "    11     2.6625     3.494461                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.49446])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=3e-3\n",
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')\n",
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ? _eos_\n",
      "which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ? _eos_\n",
      "what components of of components and and should be be be be and ? ? _eos_ _eos_\n",
      "=======================\n",
      "le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ? _eos_\n",
      "what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ? _eos_\n",
      "what is the minister of the minister to to to to the health mental mental mental and health mental health ? ? ? _eos_\n",
      "=======================\n",
      "quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux ? _eos_\n",
      "what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ? _eos_\n",
      "what are the implications of of of of workers workers workers workers workers workers workers than than than workers workers and ? ? ? ? ? _eos_ _eos_\n",
      "=======================\n",
      "que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi d’ un mois ou\n",
      "what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ? _eos_\n",
      "what if the employee employee employee employee employee the the the the or or or or the the ? ? ? ? _eos_\n",
      "=======================\n",
      "quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ? _eos_\n",
      "which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ? _eos_\n",
      "who communities , , , , , , and and of protection protection protection protection ? ? ? _eos_ _eos_\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,185):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi Directional\n",
    "\n",
    "Take all your sequences and reverse them and make a \"backwards model\" then average the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_Bidir(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        \n",
    "        # ============================= ADD AN OPTION: BIDIRECTIONAL\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        \n",
    "        # need to have an extra layer because there's 2 directions\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.05)\n",
    "        \n",
    "        # decoding\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b82f6a1643b4a638a4a0fcf3ea605d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 63/362 [00:09<00:46,  6.43it/s, loss=8.68]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-b1bed1f9e0e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/fast_dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fast_dl2/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fast_dl2/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fast_dl2/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/fast_dl2/fastai/model.py\u001b[0m in \u001b[0;36mtorch_item\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStepper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss\n",
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

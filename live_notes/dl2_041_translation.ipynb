{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating French into English\n",
    "\n",
    "- 1. Data <- `x = french,y = english sentences`\n",
    "- 2. Architecture\n",
    "- 3. Suitable loss function\n",
    "\n",
    "### Data\n",
    "\n",
    "Need a parallel corpus, we need pairs of french tuples vs. english tuples. Anything that goes through the UN has many translations. But for french, any canadian website has a french and english versions. So from scrubbing those websites we have a large set of data.\n",
    "\n",
    "#### For bounding boxes, all the interesting stuff was in the loss function, for neural translation, all the interesting stuff will be in the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Fr model for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz (39.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 39.8MB 24.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): fr-core-news-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/fr_core_news_sm\n",
      "    -->\n",
      "    /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data (2.4 GB) / Setup the directory\n",
    "~ 30 mins to download at 1MB/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 00:49:07--  http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
      "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2595102720 (2.4G) [application/x-tar]\n",
      "Saving to: ‘training-giga-fren.tar’\n",
      "\n",
      "training-giga-fren. 100%[===================>]   2.42G   149KB/s    in 47m 17s \n",
      "\n",
      "2018-05-15 01:36:24 (893 KB/s) - ‘training-giga-fren.tar’ saved [2595102720/2595102720]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.statmt.org/wmt10/training-giga-fren.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data/translate/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv training-giga-fren.tar data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf data/translate/training-giga-fren.tar -C data/translate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip data/translate/giga-fren.release2.fixed.en.gz\n",
    "!gunzip data/translate/giga-fren.release2.fixed.fr.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giga-fren.release2.fixed.en  tmp\r\n",
      "giga-fren.release2.fixed.fr  training-giga-fren.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/translate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Model takes a long time\n",
    "\n",
    "- Google's model has 8 layers\n",
    "- we are going to build a simpler one \n",
    "- Instead of a general model we will translate French questions\n",
    "\n",
    "### Tokenizing and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question regex search filters\n",
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "# grabbling lines from the english and french source texts\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "# isolate the questions\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]\n",
    "\n",
    "# save the questions for later\n",
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       "  ('Who are we?', 'Où sommes-nous?'),\n",
       "  ('Where did we come from?', \"D'où venons-nous?\"),\n",
       "  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       "  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "   'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')],\n",
       " 52331)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in pickled questions\n",
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))\n",
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that tokenizing for french is much different compared to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what', 'is', 'light', '?'],\n",
       " ['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize all the questions\n",
    "en_qs,fr_qs = zip(*qs)\n",
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))\n",
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')\n",
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are keeping tokens that are less than 30 chars\n",
    "# The filter is applied on the english words, and the same tokens are kept for french\n",
    "keep = np.array([len(o)<30 for o in en_tok])\n",
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]\n",
    "\n",
    "# save our work\n",
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    \"\"\"\n",
    "    Swaps out tokens for their index representations\n",
    "    \"\"\"\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    \n",
    "    # beginning of stream \n",
    "    itos.insert(0, '_bos_')\n",
    "    \n",
    "    # padding \n",
    "    itos.insert(1, '_pad_')\n",
    "    \n",
    "    # end of stream\n",
    "    itos.insert(2, '_eos_')\n",
    "    \n",
    "    # unknown\n",
    "    itos.insert(3, '_unk')\n",
    "    \n",
    "    # string to integer (STOI)\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi\n",
    "\n",
    "def load_ids(pre):\n",
    "    \"\"\"\n",
    "    Loading the id mapping from disk\n",
    "    \"\"\"\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))\n",
    "\n",
    "# simultaneously create and save token to indexing\n",
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')\n",
    "\n",
    "# loading lookups from scratch\n",
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 02:23:28--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.28.97\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.28.97|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10356881291 (9.6G) [application/zip]\n",
      "Saving to: ‘wiki.en.zip’\n",
      "\n",
      "wiki.en.zip         100%[===================>]   9.65G  64.1MB/s    in 2m 44s  \n",
      "\n",
      "2018-05-15 02:26:12 (60.2 MB/s) - ‘wiki.en.zip’ saved [10356881291/10356881291]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-15 02:26:12--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.113\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5975701653 (5.6G) [application/zip]\n",
      "Saving to: ‘wiki.fr.zip’\n",
      "\n",
      "wiki.fr.zip         100%[===================>]   5.56G  65.3MB/s    in 1m 44s  \n",
      "\n",
      "2018-05-15 02:27:57 (54.6 MB/s) - ‘wiki.fr.zip’ saved [5975701653/5975701653]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.en.zip\n",
      "  inflating: wiki.en.vec             \n",
      "  inflating: wiki.en.bin             \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.en.zip -C data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.fr.zip\n",
      "  inflating: wiki.fr.vec             \n",
      "  inflating: wiki.fr.bin             \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.fr.zip -C data/translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/fastText.git\n",
      "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-dxq_lk8g\n",
      "Requirement already satisfied (use --upgrade to upgrade): fasttext==0.8.22 from git+https://github.com/facebookresearch/fastText.git in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (2.2.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (39.1.0)\n",
      "Requirement already satisfied: numpy in /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22) (1.14.3)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Running setup.py bdist_wheel for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-1ctapqn4/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
      "Successfully built fasttext\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mkaggle-cli 0.12.13 has requirement lxml<4.1,>=4.0.0, but you'll have lxml 4.1.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft\n",
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))\n",
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a lookup per word to get the associated word vector\n",
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd\n",
    "\n",
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))\n",
    "\n",
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec\n",
    "\n",
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to exclude the extreme cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "\n",
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Dataset, DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)\n",
    "    \n",
    "# split the training and testing set\n",
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep], fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep], fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)\n",
    "\n",
    "# create our training and validation sets\n",
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)\n",
    "\n",
    "# set our batch size\n",
    "bs=125\n",
    "\n",
    "\"\"\"\n",
    "- Most of our preprocessing is complete so numworkers = 1\n",
    "- Padding will pad the shorter phrases to be the same length\n",
    "- Decoder, padding at the end\n",
    "- Sampler -  so we keep the similar sentences together (sorted by length) \n",
    "\"\"\"\n",
    "# arranges sentences so that similar lengths are close to each other\n",
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))\n",
    "\n",
    "# create dataloaders\n",
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 11), (21, 7), (21, 8), (33, 13), (33, 21)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek:\n",
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<img src='https://snag.gy/d6yPXD.jpg' style='width:500px'>\n",
    "\n",
    "A sequence will be parsed and encoded in the RNN and will be fed to a hidden state, and then will need to be passed to a decoder that will walk through the words one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    \"\"\"\n",
    "    Creates embedding:\n",
    "    1. rows = number of vocab\n",
    "    2. cols = embedding size dimension\n",
    "    Will randomly initialize the embedding\n",
    "    \"\"\"\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    \n",
    "    # goes through the embedding and replace\n",
    "    # the initialized weights with existing word vectors\n",
    "    # multiply x3 to compensate for the stdev 0.3\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb\n",
    "\n",
    "\n",
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder (enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        \n",
    "        # for each word, pull up the 300M vector and create an embedding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        \n",
    "        # Gru - similiar to LSTM\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        \n",
    "        # decoder (dec)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        \n",
    "        # initialize the hidden layer\n",
    "        h = self.initHidden(bs)\n",
    "        \n",
    "        # run the input through our embeddings + apply dropout\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        \n",
    "        # run it through the RNN layer\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        \n",
    "        # run the hidden state through our linear layer\n",
    "        h = self.out_enc(h)\n",
    "        \n",
    "        # ==================================================\n",
    "        # Decoder version\n",
    "        # ==================================================\n",
    "        \n",
    "        # starting with a 0 (or beginning of string _BOS_)\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        \n",
    "        # will loop as long as the longest english sentence\n",
    "        for i in range(self.out_sl):\n",
    "            \n",
    "            # embedding - we are only looking at a section at time\n",
    "            # which is why the .unsqueeze is required\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            \n",
    "            # rnn - typically works with whole phrases, but we passing\n",
    "            # only 1 unit at a time in a loop\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            \n",
    "            # dropout\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            \n",
    "            # highest probability word\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            \n",
    "            # if its padding ,we are at the end of the sentence\n",
    "            if (dec_inp==1).all(): break\n",
    "                \n",
    "        # stack the output into a single tensor\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))\n",
    "    \n",
    "\n",
    "def seq2seq_loss(input, target):\n",
    "    \"\"\"\n",
    "    Loss function - modified version of cross entropy\n",
    "    \"\"\"\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    \n",
    "    # sequence lenght could be shorter than the original\n",
    "    # need to add padding to even out the size\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "nh,nl = 256,2\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432acc9a8413438995e3c9b843c31289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 243/362 [00:33<00:16,  7.20it/s, loss=34.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model (15-20 mins to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621be1826a904b69b0fb34eaa6e6fdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.112498   5.656483  \n",
      "    1      4.331283   4.427685                              \n",
      "    2      3.890464   4.160612                              \n",
      "    3      3.613806   3.932455                              \n",
      "    4      3.428558   3.742856                              \n",
      "    5      3.352585   3.64594                               \n",
      "    6      2.988233   3.577188                              \n",
      "    7      2.938967   3.563399                              \n",
      "    8      2.957511   3.503175                              \n",
      "    9      2.996382   3.508209                              \n",
      "    10     2.666585   3.522618                              \n",
      "    11     2.6625     3.494461                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.49446])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=3e-3\n",
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')\n",
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ? _eos_\n",
      "which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ? _eos_\n",
      "what components of of components and and should be be be be and ? ? _eos_ _eos_\n",
      "=======================\n",
      "le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ? _eos_\n",
      "what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ? _eos_\n",
      "what is the minister of the minister to to to to the health mental mental mental and health mental health ? ? ? _eos_\n",
      "=======================\n",
      "quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux ? _eos_\n",
      "what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ? _eos_\n",
      "what are the implications of of of of workers workers workers workers workers workers workers than than than workers workers and ? ? ? ? ? _eos_ _eos_\n",
      "=======================\n",
      "que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi d’ un mois ou\n",
      "what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ? _eos_\n",
      "what if the employee employee employee employee employee the the the the or or or or the the ? ? ? ? _eos_\n",
      "=======================\n",
      "quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ? _eos_\n",
      "which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ? _eos_\n",
      "who communities , , , , , , and and of protection protection protection protection ? ? ? _eos_ _eos_\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,185):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi Directional\n",
    "\n",
    "Take all your sequences and reverse them and make a \"backwards model\" then average the predictions. Note that with deeper models, not all levels may be bi-directional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_Bidir(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        \n",
    "        # ============================= ADD AN OPTION: BIDIRECTIONAL\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        \n",
    "        # need to have an extra layer because there's 2 directions\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.05)\n",
    "        \n",
    "        # decoding\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss\n",
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Forcing\n",
    "\n",
    "When the model starts learning, it starts out not knowing anything about the different languages. It will eventually get better, but in the beginning it doesn't have a lot to work with. \n",
    "\n",
    "- **idea** - what if we force feed the correct answer in the beginnging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        # decoding\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        \n",
    "        # dropout\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            \n",
    "            # Given some probability we will swap out the random word\n",
    "            # with the actual correct answer\n",
    "            # at the start of training, we will have a high prob\n",
    "            # we will then decrease probability of forcing as \n",
    "            # time goes on\n",
    "            \n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on stepper\n",
    "\n",
    "```python\n",
    "class Stepper():\n",
    "    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n",
    "        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n",
    "        self.fp16 = fp16\n",
    "        self.reset(True)\n",
    "        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n",
    "        self.loss_scale = loss_scale\n",
    "\n",
    "    def reset(self, train=True):\n",
    "        if train: apply_leaf(self.m, set_train_mode)\n",
    "        else: self.m.eval()\n",
    "        if hasattr(self.m, 'reset'):\n",
    "            self.m.reset()\n",
    "            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n",
    "\n",
    "    # ======================================================\n",
    "    # This section will be replaced Seq2Seq\n",
    "    # ======================================================    \n",
    "    def step(self, xs, y, epoch):\n",
    "        xtra = []\n",
    "        \n",
    "        #  ========= calls the model\n",
    "        output = self.m(*xs)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "            \n",
    "        #  =========  zeroes out gradient\n",
    "        if self.fp16: self.m.zero_grad()\n",
    "        else: self.opt.zero_grad() \n",
    "            \n",
    "        #  =========  calculates loss\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "            \n",
    "        #  =========  calls backwards\n",
    "        loss.backward()\n",
    "        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n",
    "        if self.loss_scale != 1:\n",
    "            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n",
    "                \n",
    "        #  =========  gradient clipping if necessary\n",
    "        if self.clip:\n",
    "            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n",
    "            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "                \n",
    "        #  =========  calls optimizer\n",
    "        self.opt.step()\n",
    "        if self.fp16: \n",
    "            copy_fp32_to_model(self.m, self.fp32_params)\n",
    "            torch.cuda.synchronize()\n",
    "        return torch_item(raw_loss.data)\n",
    "\n",
    "    # ======================================================\n",
    "    # ======================================================    \n",
    "\n",
    "    def evaluate(self, xs, y):\n",
    "        preds = self.m(*xs)\n",
    "        if isinstance(preds,tuple): preds=preds[0]\n",
    "        return preds, self.crit(preds, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the `step` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    \"\"\"\n",
    "    By default Stepper class calls 'step'\n",
    "    \"\"\"\n",
    "    def step(self, xs, y, epoch):\n",
    "        \n",
    "        # replace pr_force with something that \n",
    "        # gradually decreases, and eventually goes to 0\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        \n",
    "        # === the same\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Model\n",
    "\n",
    "Our RNN model exports the hidden state at every time step, along with the hidden state at the last time step. Initially we are only using the LAST hidden state to 'decode' into another phrase\n",
    "\n",
    "```python\n",
    "enc_out, h = self.gru_enc(emb, h)\n",
    "h = self.out_enc(h)\n",
    "```\n",
    "\n",
    "**can we use the rest of those hidden states?** \n",
    "\n",
    "**goal**: use some % of all hidden states and add another trainable parameter to find good answers in the model\n",
    "\n",
    "**idea** - expecting the entire sentence to be summarized into a vector is a lot. Instead of having a hidden state at the end of the phrase, we can have a hidden state after every single word. So how do we use the hidden information after every word. \n",
    "\n",
    "<img src='https://snag.gy/QGdcZl.jpg' style='width:500px'>\n",
    "<img src='https://snag.gy/YZuNDH.jpg' style='width:500px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttnRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec*2, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        # random matrix\n",
    "        self.W1 = rand_p(nh, em_sz_dec)\n",
    "        \n",
    "        # this is the mini NN that will calculate the weights\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        \n",
    "        self.l3 = nn.Linear(em_sz_dec+nh, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None, ret_attn=False):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            \n",
    "            # create a little neural network\n",
    "            # will use softmax to generate the \n",
    "            # probabilities\n",
    "            \n",
    "            # take last layers hidden state put into lin layer\n",
    "            w2h = self.l2(h[-1])\n",
    "            \n",
    "            # nonlinear activation\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            \n",
    "            # matrix multiply\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            \n",
    "            # take a weighted average. Use the weights from NN\n",
    "            # note we are using all the encoder states\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            \n",
    "            # adding the hidden states to the encoder weights\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "\n",
    "        res = torch.stack(res)\n",
    "        if ret_attn: res = res,torch.stack(attns)\n",
    "        return res\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqAttnRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss\n",
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs,attns = learn.model(V(x),ret_attn=True)\n",
    "preds = to_np(probs.max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets check the attention distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = to_np(attns[...,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.plot(attn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporate all the ideas\n",
    "- Bidirectional\n",
    "- Teacher Forcing\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_All(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh*2, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh*2, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

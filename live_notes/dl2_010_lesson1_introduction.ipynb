{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lesson 14\n",
    "\n",
    "### Where we are:\n",
    "<img src='https://snag.gy/xdIU7u.jpg' style='width:600px'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Differentiable Layers** - coined by Yann Lecun, we don't call it deep learning but differentiable deep learning. In part 1, we setup a diff'able function and a loss function that explains how good the parameters are. If you can define a loss function to score a task, and you have a flexible NN, you are done.\n",
    "\n",
    "        Yeah, Differentiable Programming is little more than a rebranding of the modern collection Deep Learning techniques, the same way Deep Learning was a rebranding of the modern incarnations of neural nets with more than two layers.\n",
    "        The important point is that people are now building a new kind of software by assembling networks of parameterized functional blocks and by training them from examples using some form of gradient-based optimization….It’s really very much like a regular program, except it’s parameterized, automatically differentiated, and trainable/optimizable.\n",
    "        Yann LeCun, Director of FAIR\n",
    "\n",
    "2. **Transfer Learning** - you should never need to start on random data. You should only start if no one has every solved a problem that is remotely close or related to what you are trying to solve. Fastai's focus is completely focused on transfer learning and as a result the library is much different than any other library.  In short, transfer learning takes a trained model, takes away the last few layers, retrains the last few layers, fine tunes the entire architecture, and as a result, trains a lot faster and requires less data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/9Bsj78.jpg' style='width:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.**Architecture Design** - There's only a few models that generally cover a majority of problems. In part 1, we generally focused on activation functions and the output. We spend less time talking about architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/q3Wv9m.jpg' width='600px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.** how to Avoid overfitting ** - Create somethign that is over-parameterized. Train it for sure, overfit it, which guarantees that there is a predictive capability. Then we use the following techniques to reduce the overfitting to arrive at a generalized model.\n",
    "\n",
    "- Get more data\n",
    "- Data augmentation\n",
    "- Generalized Architecture\n",
    "- regularization\n",
    "- Lastly, reduce architecture complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= 'https://snag.gy/pSmn4z.jpg' style = 'width:600px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.**Embeddings** - Just earlier last year, there was fewer discussions of using embeddings in tabular data (vs. the NLP related topics) Now these days there are more and more examples of using embeddings in traditional structured tabular data settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://snag.gy/fVBUX2.jpg' style='width:600px' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2's Goals / Approach\n",
    "\n",
    "Part 1 was an introduction to best practices. Overviewed mature techniques that were reasonably reliable for a wide variety of real world problems. These techniques were developed and tested over a longer period of time. **Cutting Edge** means that the best parameters may not always be evident. It may or may not be the absolute best solution, and the fastai implementation may still be buggy. The techniques covered will be promising in the research world, but may require tweaking. It's exciting to work with the most current techniques and to also learn these recent techniques and understand what is going on vs. the recipe and pre-built libraries of pytorch and fastai.\n",
    "\n",
    "\n",
    "#### Some caveats:\n",
    "- Requires fastai customization\n",
    "- Need to understand python well\n",
    "- Other code resources will generally be research quality\n",
    "- Code samples online nearly have always have problems\n",
    "- Each lesson will be incomplete, ideas to explore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are considering building your own box checkout the forums.\n",
    "<img src='https://snag.gy/HZpRiw.jpg' style='width:600px' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's time to start reading papers\n",
    "\n",
    "Each week we will be implementing a paper. In academic papers love using greek letters. Academics never refactor or substitute, but equations can get very long. Academic papers can be weird, but its the current way that research is commuted these days.\n",
    "\n",
    "#### Since this is all cutting-edge, its a great opportunity!\n",
    "\n",
    "- make a blog post, explain things in plain language\n",
    "- maybe a simple implementation that other people can use\n",
    "- use a published case study and translate the technique to a similar problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://snag.gy/cb1w3V.jpg' style='width:600px' >\n",
    "<img src='https://snag.gy/ESuAX9.jpg' style='width:600px' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2's Topics\n",
    "\n",
    "<img src='https://snag.gy/V2cXTx.jpg' style='width:600px'>\n",
    "\n",
    "#### Generative models\n",
    "\n",
    "NN's generally output numbers. But now the outputs will be locations of objects, or a complete picture with a class in every pixel. Or an enhanced super-resolution of an image. Or text translated into french. Requires some different ways of thinking about things and different architectures.\n",
    "\n",
    "\n",
    "#### Data: Text or Image data\n",
    "\n",
    "#### Larger datasets - more objects and size of files\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10 - Borrowing from Darknet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from fastai.conv_learner import *\n",
    "PATH = Path(\"data/cifar10/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n",
      "0\n",
      "Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://pjreddie.com/media/files/cifar.tgz -U data/cifar10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mv cifar.tgz data/cifar10/\n",
    "# ! tar -xf data/cifar10/cifar.tgz -C data/cifar10/\n",
    "# ! ls data/cifar10/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some basic folder structure to store all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/cifar10/cifar/'\n",
    "OUTPATH = 'data/cifar10/'\n",
    "# for x in classes:\n",
    "#     os.makedirs(OUTPATH+'train/'+x,exist_ok=True)\n",
    "#     os.makedirs(OUTPATH+'val/'+x,exist_ok=True)\n",
    "    \n",
    "# # check how many files are in the original directory\n",
    "# # note that all these files are in a single directory\n",
    "# filenames = os.listdir(PATH +'train/')\n",
    "# counts = {x:0 for x in classes}\n",
    "# print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this part of the code will cycle through each class\n",
    "# # and make a sub dir in train and val\n",
    "# # EXAMPLE:\n",
    "# # train/car/ ... images\n",
    "# # val/car/ ... images\n",
    "\n",
    "# valset_size = len(filenames) / 10 * .2\n",
    "# for file_n in filenames:\n",
    "#     for x in classes:\n",
    "#         if x in file_n:\n",
    "#             counts[x] = counts[x] +1\n",
    "#             if counts[x] < valset_size:\n",
    "#                 shutil.copyfile(PATH+'train/'+file_n, OUTPATH+'val/'+x+'/'+file_n)\n",
    "#             else:\n",
    "#                 shutil.copyfile(PATH+'train/'+file_n, OUTPATH+'train/'+x+'/'+file_n)\n",
    "#         if 'automobile' in file_n:\n",
    "#             counts['car'] = counts['car'] +1\n",
    "#             if counts[x] < valset_size:\n",
    "#                 shutil.copyfile(PATH+'train/'+file_n, OUTPATH+'val/car/'+file_n)\n",
    "#             else:\n",
    "#                 shutil.copyfile(PATH+'train/'+file_n, OUTPATH+'train/car/'+file_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some parameters\n",
    "num_workers = num_cpus()//2\n",
    "\n",
    "# batch size\n",
    "bs=256\n",
    "\n",
    "# image size\n",
    "sz=32\n",
    "\n",
    "# define which transformations we will be using\n",
    "# we will only be using flips (will skip rotations since images are small)\n",
    "# random flips and 4 pixels of padding on each side. Doesn't add black padding\n",
    "# FASTAI - takes the last few pixels and reflect it for a border\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8)\n",
    "\n",
    "# create our image data\n",
    "data = ImageClassifierData.from_paths(OUTPATH, val_name='val', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "Further research into the exploration of 2 / 3 conv_block layers. What size should the channels be? What happens under difference size configurations. Check out this paper:\n",
    "\n",
    "https://arxiv.org/abs/1605.07146\n",
    "\n",
    "- ** may not be good to decrease --> increase ** even though it permits more layers\n",
    "- paper reviews best practices for choosing GPUs and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Architecture\n",
    "# ===============================================\n",
    "'''\n",
    "Darknet\n",
    "| - ResLayer\n",
    "      | - Conv_layer\n",
    "'''\n",
    "\n",
    "def conv_layer(ni, nf, ks=3, stride=1):\n",
    "    \"\"\"\n",
    "    Using a sequential layer instead of a custom nn.Module\n",
    "    Much easier, since we are using standard blocks\n",
    "    \n",
    "    ni: number of inputs\n",
    "    nf: number of filters\n",
    "    ks: kernel size\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, \n",
    "                  nf, \n",
    "                  kernel_size=ks, \n",
    "                  bias=False, \n",
    "                  stride=stride, \n",
    "                  padding=ks//2),\n",
    "        \n",
    "        nn.BatchNorm2d(nf, \n",
    "                       momentum=0.01),\n",
    "        \n",
    "        nn.LeakyReLU(negative_slope=0.1, \n",
    "                     inplace=True))\n",
    "\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the standard res layer (resnet). The key feature\n",
    "    is adding the input along with the convoluted input. This\n",
    "    is found in the forward()\n",
    "    \n",
    "    OUTPUT = INPUT + CONV_BLOCK2(CONV_BLOCK1(INPUT))\n",
    "    \n",
    "    ni : number of inputs\n",
    "    \n",
    "    Number of channels: will squash to input channels //2\n",
    "    \n",
    "    EXAMPLE:\n",
    "    --------\n",
    "        64 input => conv1 => 32 => conv2 => 64\n",
    "    \"\"\"\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1=conv_layer(ni, ni//2, ks=1)\n",
    "        self.conv2=conv_layer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): return x.add_(self.conv2(self.conv1(x)))\n",
    "\n",
    "    \n",
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        \"\"\"\n",
    "        \n",
    "        ch_in: channels in \n",
    "        \n",
    "        A. conv_block:\n",
    "        1. will double the number of layers in\n",
    "        2. have the grid size\n",
    "        \n",
    "        B. collection of res_blocks\n",
    "        3. then do a bunch of resLayers (constant channels)\n",
    "        \"\"\"\n",
    "        return [conv_layer(ch_in, ch_in*2,stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, nf=32):\n",
    "        \"\"\"\n",
    "        Expects a creation such as \n",
    "        \n",
    "        model = Darknet([1,2,4,6,3], num_classes=10, nf=32)\n",
    "        \n",
    "        -> Initial conv_block\n",
    "        -> 1 x group layer [ conv_block + 1 x res_block] w/ 32 filters (64 channels out)\n",
    "        -> 1 x group layer [ conv_block + 2 x res_block] w/ 32 filters (128 channels out)\n",
    "        -> 1 x group layer [ conv_block + 4 x res_block] w/ 32 filters (256 channels out)\n",
    "        -> 1 x group layer [ conv_block + 6 x res_block] w/ 32 filters (512 channels out)\n",
    "        -> 1 x group layer [ conv_block + 3 x res_block] w/ 32 filters (1024 channels out)\n",
    "        -> AdaptiveAvgPool\n",
    "        -> Flatten\n",
    "        -> Fully Connected Linear Layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = [conv_layer(3, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            \n",
    "            # first layer has a stride of 1 so we don't halve the size of \n",
    "            # small images\n",
    "            layers += self.make_group_layer(nf, nb, stride=2-(i==1))\n",
    "            nf *= 2\n",
    "        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an initial model\n",
    "m = Darknet([1, 2, 4, 6, 3], num_classes=10, nf=32)\n",
    "m = nn.DataParallel(m, [1,2,3])\n",
    "\n",
    "# set the learning rate\n",
    "lr = 1.3\n",
    "\n",
    "# create our model\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20, 20, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Features used\n",
    "\n",
    "- tesla GPUS on AWS P3 - 8 GPUs\n",
    "- floating point 16 (half/precision) , using volta's half precision capabilities\n",
    "- single cycle learning rate\n",
    "\n",
    "\n",
    "#### Reminder of one cycle learning\n",
    "\n",
    "- Creates a upward path as long as the downward path\n",
    "- choose a ratio between two numbers x/y\n",
    "- what % of your epoches are spent going from low part of triangle down to zero\n",
    "- Momentum is also included, and correlates inverted.\n",
    "<img src='https://snag.gy/hxUyw1.jpg' style='width:600px'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
